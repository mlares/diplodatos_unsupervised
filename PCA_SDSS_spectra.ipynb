{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous example, this notebook assumes that the current\n",
    "working directory is in the scikit-learn tutorial directory where\n",
    "the notebook is stored. In the folder\n",
    "\n",
    "     ../data/sdss_spectra\n",
    "\n",
    "you’ll find the script which fetches a set of spectra from the\n",
    "Sloan Digital Sky Survey. Each individual spectrum is at a particular\n",
    "redshift, and can have data missing in certain spectral regions. So\n",
    "that this doesn’t affect our analysis, the spectra have been de-redshifted\n",
    "and the gaps have been filled using the PCA-based algorithm described in.\n",
    "In the process of shifting and gap-filling, the spectra have been\n",
    "down-sampled so that the number of attributes is n = 1000.\n",
    "\n",
    "If you're using a different directory structure, then the ``DATA_HOME``\n",
    "variable in the following script should be set accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_HOME = os.path.abspath('../data/sdss_spectra/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is downloaded, it can be read-in as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/store/TeachJob/AstrometriaI/pythings/data/sdss_spectra/spec4000_corrected.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6381108b22ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_HOME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'spec4000_corrected.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/store/TeachJob/AstrometriaI/pythings/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/store/TeachJob/AstrometriaI/pythings/data/sdss_spectra/spec4000_corrected.npz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(os.path.join(DATA_HOME,'spec4000_corrected.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case ``data`` is a ``npz`` archive, consisting of several arrays\n",
    "zipped together.  We can see the various arrays in the ``files`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable X contains 4000 spectra, each with 1000 attributes. In addition,\n",
    "the file includes a classification code y, and redshift z for each spectrum,\n",
    "and an array wavelengths which can aid in plotting spectra. Let’s plot a few\n",
    "of these to see what they look like, making sure to choose a representative\n",
    "of each of the interesting classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectral_types(data):\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    wavelengths = data['wavelengths']\n",
    "    labels = data['labels']\n",
    "\n",
    "    for i_class in (2, 3, 4, 5, 6):\n",
    "        i = np.where(y == i_class)[0][0]\n",
    "        l = pl.plot(wavelengths, X[i] + 20 * i_class)\n",
    "        c = l[0].get_color()\n",
    "        pl.text(6800, 2 + 20 * i_class, labels[i_class], color=c)\n",
    "   \n",
    "    pl.subplots_adjust(hspace=0)\n",
    "    pl.xlabel('wavelength (Angstroms)')\n",
    "    pl.ylabel('flux + offset')\n",
    "    pl.title('Sample of Spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectral_types(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4000 spectra in this file, each with 1000 attributes. Visualizing\n",
    "a dataset of this size can be very difficult. We could plot all 4000 spectra\n",
    "as we did above, but the plot would quickly become too complicated. As a\n",
    "first step, it might be helpful to ask what the average spectrum looks like.\n",
    "To do this, we’ll plot the mean, but first we’ll normalize the spectra.\n",
    "Because the spectra represent galaxies at distances that range over several\n",
    "hundreds of light-years, their total flux varies greatly. Thus it will\n",
    "help if we normalize the spectra. For this we’ll use the scikit-learn\n",
    "preprocessing module. We’ll then plot both the mean and standard\n",
    "deviation to give us an idea of the data we’re working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def plot_mean_std(data):\n",
    "    X = data['X']\n",
    "    wavelengths = data['wavelengths']\n",
    "    \n",
    "    X = normalize(X)\n",
    "    mu = X.mean(0)\n",
    "    std = X.std(0)\n",
    "    pl.plot(wavelengths, mu, color='black')\n",
    "    pl.fill_between(wavelengths, mu - std, mu + std, color='#CCCCCC')\n",
    "    pl.xlim(wavelengths[0], wavelengths[-1])\n",
    "    pl.ylim(0, 0.06)\n",
    "    pl.xlabel('wavelength (Angstroms)')\n",
    "    pl.ylabel('scaled flux')\n",
    "    pl.title('Mean Spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviation of the normalized spectra. Some of\n",
    "the largest variation is found at wavelengths at which Hydrogen\n",
    "absorbs and emits photons (Hydrogen is by far the most abundant\n",
    "atom in the universe). For example, the line at 6563 is known as\n",
    "Hydrogen-$\\alpha$, and is often seen in emission (spiking up) in\n",
    "quasars and other active galaxies.\n",
    "\n",
    "The interesting part of the data is in the gray shaded regions: how\n",
    "do spectra vary from the mean, and how can this variation tell us\n",
    "about their physical properties? One option to visualize this would\n",
    "be to scatter-plot random pairs of observations from each spectrum.\n",
    "We’ll first create a formatter object to make the colorbar labels pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def plot_random_projection(data, rseed=25255):\n",
    "    # rseed is chosen to emphasize correlation\n",
    "    np.random.seed(rseed)  \n",
    "    i1, i2 = np.random.randint(1000, size=2)\n",
    "    \n",
    "    # create a formatter which works for our labels\n",
    "    format = pl.FuncFormatter(lambda i, *args: labels[i].replace(' ', '\\n'))\n",
    "    \n",
    "    X = normalize(data['X'])\n",
    "    y = data['y']\n",
    "    labels = data['labels']\n",
    "    wavelengths = data['wavelengths']\n",
    "    \n",
    "    pl.scatter(X[:, i1], X[:, i2], c=y, s=4, lw=0,\n",
    "               vmin=2, vmax=6, cmap=pl.cm.jet)\n",
    "    pl.colorbar(ticks = range(2, 7), format=format)\n",
    "    pl.xlabel('wavelength = %.1f' % wavelengths[i1])\n",
    "    pl.ylabel('wavelength = %.1f' % wavelengths[i2])\n",
    "    pl.title('Random Pair of Spectra Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_projection(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear correlation between these two measurements. That is,\n",
    "if you know the value of one, then you could quite accurately predict\n",
    "the value of the other. This shows us that some of the spectral bins\n",
    "do not add much information, and can be ignored. One could imagine\n",
    "proceeding by trial and error, plotting pairs of points and seeing which\n",
    "ones provide the most interesting information, but this would be very\n",
    "tedious. Instead, we can use an automated technique for dimensionality\n",
    "reduction, one well-known example of which is Principal Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is an often-used tool in astronomy\n",
    "and other data-intensive sciences. In a sense, it automates the\n",
    "trial-and-error process discussed in the previous section, and finds\n",
    "the most interesting linear combinations of attributes, so that\n",
    "high-dimensional data can be visualized in a 2D or 3D plot. Scikit-learn\n",
    "has methods to compute PCA and several variants. Classic PCA\n",
    "(sklearn.decomposition.PCA) is based on an eigenvalue decomposition of\n",
    "the data covariance, so that for N points, the computational cost grows\n",
    "as $\\mathcal{O}[N^3]$. This means that for large datasets like the current\n",
    "one, the fit can be very slow. You can try it as follows, but the\n",
    "computation may take up to several minutes for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "X = data['X']\n",
    "\n",
    "# warning: this next command takes a long time!\n",
    "#X_projected = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, scikit-learn has an alternative method that is much faster.\n",
    "The speed comes at a price: it is based on random projections, so the\n",
    "results are not as robust as the normal method. But for tasks such as\n",
    "ours where we are seeking only a few of a large number of eigenvectors,\n",
    "it performs fairly well. To keep our results consistent between runs,\n",
    "we’ll explicitly set the random seed for the fit. You should repeat this\n",
    "with several different random seeds to convince yourself that the results\n",
    "are consistent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA\n",
    "rpca = RandomizedPCA(n_components=4, random_state=0)\n",
    "\n",
    "X = normalize(data['X'])\n",
    "X_proj = rpca.fit_transform(X)\n",
    "\n",
    "print X_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``X_proj`` is now a reduced-dimension representation of ``X``, where the lower-index columns are the most important dimensions. We can visualize the spectra now using the first two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA_projection(data, rpca):\n",
    "    y = data['y']\n",
    "    \n",
    "    # create a formatter which works for our labels\n",
    "    labels = data['labels']\n",
    "    format = pl.FuncFormatter(lambda i, *args: labels[i].replace(' ', '\\n'))\n",
    "    \n",
    "    X_proj = rpca.transform(X)\n",
    "\n",
    "    pl.scatter(X_proj[:, 0], X_proj[:, 1], c=y, s=4, lw=0, vmin=2, vmax=6, cmap=pl.cm.jet)\n",
    "    pl.colorbar(ticks = range(2, 7), format=format)\n",
    "    pl.xlabel('coefficient 1')\n",
    "    pl.ylabel('coefficient 2')\n",
    "    pl.title('PCA projection of Spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA_projection(data, rpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a two-dimensional visualization, but what does this tell us? Looking at the PCA model in the equation above, we see that each component is associated with an eigenvector, and this plot is showing $a_{i1}$ and $a_{i2}$ where\n",
    "\n",
    "   $\\vec{s_i} \\approx \\vec{\\mu} + a_{i1}\\vec{v_1} + a_{i2}\\vec{v_2}$\n",
    "\n",
    "Visualizing the eigenvectors $\\vec{v_j}$ can give insight into what these components mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eigenvectors(data, rpca):\n",
    "    wavelengths = data['wavelengths']\n",
    "    \n",
    "    l = pl.plot(wavelengths, rpca.mean_ - 0.15)\n",
    "    c = l[0].get_color()\n",
    "    pl.text(7000, -0.16, \"mean\", color=c)\n",
    "    \n",
    "    for i in range(4):\n",
    "        l = pl.plot(wavelengths, rpca.components_[i] + 0.15 * i)\n",
    "        c = l[0].get_color()\n",
    "        pl.text(7000, -0.01 + 0.15 * i, \"component %i\" % (i + 1), color=c)\n",
    "        \n",
    "    pl.ylim(-0.2, 0.6)\n",
    "    pl.xlabel('wavelength (Angstroms)')\n",
    "    pl.ylabel('scaled flux + offset')\n",
    "    pl.title('Mean Spectrum and Eigen-spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigenvectors(data, rpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first eigenspectrum (component 1) tells us about the\n",
    "relative difference in flux between low wavelengths and high wavelengths\n",
    "- that is, the color of the spectrum. Component 2 tells us a lot about\n",
    "the emission and absorption characteristics in the various lines, and\n",
    "also in the so-called “4000 angstrom break” due to Hydrogen absorption.\n",
    "Detailed analysis of these components and eigenspectra can lead to much\n",
    "physical insight about the galaxies in the fit.\n",
    "\n",
    "Nevertheless, there are some weaknesses here. First of all, PCA does not\n",
    "do a good job of separating out galaxies with different emission\n",
    "characteristics. We’d hope for a projection which reflects the fact that\n",
    "narrow spectral features are very important in the classification. PCA\n",
    "does not do this. In a later exercise, we’ll explore some alternative\n",
    "nonlinear dimensionality reduction techniques which will address this\n",
    "deficiency of PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
