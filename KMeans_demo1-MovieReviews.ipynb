{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiploDatos 2018 / Aprendizaje no supervizado / Clustering Demo*\n",
    "\n",
    "# Aplicación de técnicas de *clustering* a documentos de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivos:**\n",
    "\n",
    "En este ejemplo mostraremos cómo utilizar técnicas de clustering para aprender la estructura subyacente de un conjunto de documentos de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### DATOS: Top 100 Greatest Movies of All Time (The Ultimate List), by ChrisWalczyk55\n",
    "\n",
    "https://www.imdb.com/list/ls055592025/\n",
    "\n",
    "El problema consiste en agrupar un conjunto de películas en base a sus críticas en inglés, \n",
    "usando para ello procesamiento del texto\n",
    "\n",
    "\n",
    "Lo primero que haremos es leer los datos, disponibles en:\n",
    "https://github.com/brandomr/document_cluster.git\n",
    "\n",
    "\n",
    "### Leer el conjunto de *títulos* de las películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Godfather', 'The Shawshank Redemption', \"Schindler's List\", 'Raging Bull', 'Casablanca', \"One Flew Over the Cuckoo's Nest\", 'Gone with the Wind', 'Citizen Kane', 'The Wizard of Oz', 'Titanic', 'Lawrence of Arabia', 'The Godfather: Part II', 'Psycho', 'Sunset Blvd.', 'Vertigo', 'On the Waterfront', 'Forrest Gump', 'The Sound of Music', 'West Side Story', 'Star Wars', 'E.T. the Extra-Terrestrial', '2001: A Space Odyssey', 'The Silence of the Lambs', 'Chinatown', 'The Bridge on the River Kwai', \"Singin' in the Rain\", \"It's a Wonderful Life\", 'Some Like It Hot', '12 Angry Men', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb', 'Amadeus', 'Apocalypse Now', 'Gandhi', 'The Lord of the Rings: The Return of the King', 'Gladiator', 'From Here to Eternity', 'Saving Private Ryan', 'Unforgiven', 'Raiders of the Lost Ark', 'Rocky', 'A Streetcar Named Desire', 'The Philadelphia Story', 'To Kill a Mockingbird', 'An American in Paris', 'The Best Years of Our Lives', 'My Fair Lady', 'Ben-Hur', 'Doctor Zhivago', 'Patton', 'Jaws', 'Braveheart', 'The Good, the Bad and the Ugly', 'Butch Cassidy and the Sundance Kid', 'The Treasure of the Sierra Madre', 'The Apartment', 'Platoon', 'High Noon', 'Dances with Wolves', 'The Pianist', 'Goodfellas', 'The Exorcist', 'The Deer Hunter', 'All Quiet on the Western Front', 'The French Connection', 'City Lights', \"The King's Speech\", 'It Happened One Night', 'A Place in the Sun', 'Midnight Cowboy', 'Mr. Smith Goes to Washington', 'Rain Man', 'Annie Hall', 'Out of Africa', 'Good Will Hunting', 'Terms of Endearment', 'Tootsie', 'Fargo', 'Giant', 'The Grapes of Wrath', 'Shane', 'The Green Mile', 'Close Encounters of the Third Kind', 'Network', 'Nashville', 'The Graduate', 'American Graffiti', 'Pulp Fiction', 'The African Queen', 'Stagecoach', 'Mutiny on the Bounty', 'The Maltese Falcon', 'A Clockwork Orange', 'Taxi Driver', 'Wuthering Heights', 'Double Indemnity', 'Rebel Without a Cause', 'Rear Window', 'The Third Man', 'North by Northwest', 'Yankee Doodle Dandy']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/document_cluster/title_list.txt\") as file:\n",
    "    titles = [line.strip() for line in file]\n",
    "    \n",
    "print (titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer el conjunto de *críticas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "synopses = []\n",
    "\n",
    "with open(\"data/document_cluster/synopses_list_wiki.txt\") as file:\n",
    "    i = True\n",
    "    l = ' '\n",
    "    for line in file:            \n",
    "        if 'BREAKS HERE' in line:\n",
    "            synopses.append(l) # append the previously collected lines\n",
    "            l = ' '\n",
    "        \n",
    "        l = l + line.strip()\n",
    "        \n",
    "print (len(synopses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer conjunto de *géneros*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/document_cluster/genres_list.txt\") as file:\n",
    "    genres = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Godfather\n",
      "[u' Crime', u' Drama']\n",
      " Plot  [edit]  [  [  edit  edit  ]  ]On the day of his only daughter's wedding, Vito Corleone hears requests in his role as the Godfather, the Don of a New York crime family. Vito's youngest son, Michael, in a Marine Corps uniform, introduces his girlfriend, Kay Adams, to his family at the sprawling reception. Vito's godson Johnny Fontane, a popular singer, pleads for help in securing a coveted movie role, so Vito dispatches his consigliere, Tom Hagen, to Los Angeles to influence the abrasive studio head, Jack Woltz. Woltz is unmoved until the morning he wakes up in bed with the severed head of his prized stallion.  On the day of his only daughter's wedding,   Vito Corleone  Vito Corleone   hears requests in his role as the Godfather, the   Don  Don   of a New York crime family. Vito's youngest son,   Michael  Michael  , in a   Marine Corps  Marine Corps   uniform, introduces his girlfriend,   Kay Adams  Kay Adams  , to his family at the sprawling reception. Vito's godson   Johnny Fontane  Johnny Fontane  , a popular singer, pleads for help in securing a coveted movie role, so Vito dispatches his   consigliere  consigliere  ,   Tom Hagen  Tom Hagen  , to Los Angeles to influence the abrasive studio head,   Jack Woltz  Jack Woltz  . Woltz is unmoved until the morning he wakes up in bed with the severed head of his prized   stallion  stallion  .Shortly before Christmas 1945, drug baron Virgil \"The Turk\" Sollozzo, backed by the Corleones' rivals, the Tattaglias, asks Vito for investment in the emerging drug trade and protection through his political connections. Vito disapproves of drug dealers, so he sends his enforcer, Luca Brasi, to spy on them. The family then receives two fish wrapped in Brasi's vest, imparting that he \"sleeps with the fishes\". An assassination attempt by Sollozzo's men lands Vito in the hospital, so his eldest son, Sonny, takes command. Sollozzo kidnaps Hagen to pressure Sonny to accept his deal. Michael thwarts a second assassination attempt on his father at the hospital; his jaw is broken by Police Captain McCluskey, who is also Sollozzo's bodyguard. Sonny retaliates for the attacks on his father by having Tattaglia's son killed. Michael comes up with a plan to hit Sollozzo and McCluskey: on the pretext of settling the dispute, Michael accepts their offer to meet in a Bronx restaurant and, retrieving a planted handgun, murders them.  Shortly before Christmas 1945, drug baron   Virgil \"The Turk\" Sollozzo  Virgil \"The Turk\" Sollozzo  , backed by the Corleones' rivals, the Tattaglias, asks Vito for investment in the emerging drug trade and protection through his political connections. Vito disapproves of drug dealers, so he sends his enforcer,   Luca Brasi  Luca Brasi  , to spy on them. The family then receives two fish wrapped in Brasi's vest, imparting that he \"sleeps with the fishes\". An assassination attempt by Sollozzo's men lands Vito in the hospital, so his eldest son,   Sonny  Sonny  , takes command. Sollozzo kidnaps Hagen to pressure Sonny to accept his deal. Michael thwarts a second assassination attempt on his father at the hospital; his jaw is broken by Police Captain McCluskey, who is also Sollozzo's bodyguard. Sonny retaliates for the attacks on his father by having Tattaglia's son killed. Michael comes up with a plan to hit Sollozzo and McCluskey: on the pretext of settling the dispute, Michael accepts their offer to meet in a Bronx restaurant and, retrieving a planted handgun, murders them.Despite a clampdown from the authorities, the Five Families erupt in open warfare and the brothers fear for their safety. Michael takes refuge in Sicily, and Fredo Corleone is sheltered by associate Moe Greene in Las Vegas. Sonny attacks his brother-in-law Carlo on the street for abusing his sister Connie and threatens to kill him if he abuses her again. When it happens again, Sonny speeds for her home but assassins ambush him at a highway toll booth and riddle him with submachine gun fire. Michael's time abroad has led to marriage to Apollonia Vitelli. Their euphoria is shattered when a car bomb intended for him takes her life.  Despite a clampdown from the authorities, the   Five Families  Five Families   erupt in open warfare and the brothers fear for their safety. Michael takes refuge in Sicily, and   Fredo Corleone  Fredo Corleone   is sheltered by associate   Moe Greene  Moe Greene   in   Las Vegas  Las Vegas  . Sonny attacks his brother-in-law   Carlo  Carlo   on the street for abusing his sister Connie and threatens to kill him if he abuses her again. When it happens again, Sonny speeds for her home but assassins ambush him at a highway toll booth and riddle him with submachine gun fire. Michael's time abroad has led to marriage to Apollonia Vitelli. Their euphoria is shattered when a car bomb intended for him takes her life.Devastated by Sonny's death, Vito decides to end the feuds. Realising that the Tattaglias were under orders of the now dominant Don Emilio Barzini, he promises, before the heads of the Five Families, to withdraw his opposition to their heroin business and forgo revenge for his son's murder. His safety guaranteed, Michael returns home to a father saddened by his involvement in the family business and marries Kay the next year.  Devastated by Sonny's death, Vito decides to end the feuds. Realising that the Tattaglias were under orders of the now dominant Don   Emilio Barzini  Emilio Barzini  , he promises, before the heads of the Five Families, to withdraw his opposition to their heroin business and forgo revenge for his son's murder. His safety guaranteed, Michael returns home to a father saddened by his involvement in the family business and marries Kay the next year.With his father at the end of his career and his surviving brother too weak, Michael takes the reins of the family, promising Kay that he will make the business legitimate within five years. To that end, he insists Hagen relocate to Las Vegas and relinquish his role to Vito because Tom is not a \"wartime consigliere\"; the older man agrees Tom should \"have no part in what will happen\" in the coming battles with rival families. When Michael travels to Las Vegas to buy out Greene's stake in the family's casinos, Greene derides the Corleones as a fading power. To add injury to insult, Michael sees Fredo falling under Greene's sway.  With his father at the end of his career and his surviving brother too weak, Michael takes the reins of the family, promising Kay that he will make the business legitimate within five years. To that end, he insists Hagen relocate to Las Vegas and relinquish his role to Vito because Tom is not a \"wartime consigliere\"; the older man agrees Tom should \"have no part in what will happen\" in the coming battles with rival families. When Michael travels to Las Vegas to buy out Greene's stake in the family's casinos, Greene derides the Corleones as a fading power. To add injury to insult, Michael sees Fredo falling under Greene's sway.Vito collapses and dies in his garden while playing with Michael's son, Anthony. At the funeral, Salvatore Tessio arranges a meeting between Michael and Don Barzini, signalling his treachery as Vito had warned. The meeting is set for the same day as the christening of Connie's son, to whom Michael will stand as godfather. As the christening proceeds, Corleone assassins, acting on Michael's orders, murder the other New York dons and Moe Greene. Tessio is told that Michael is aware of his betrayal and taken off to his death. After Carlo is questioned by Michael on his involvement in setting up Sonny's murder and confesses he was contacted by Barzini, Peter Clemenza kills him with a wire garrote. Michael is confronted by Connie, who accuses him of having her husband killed. He denies killing Carlo when questioned by Kay, an answer she accepts. As Kay watches warily, Michael receives his capos, who address him as the new Don Corleone.  Vito collapses and dies in his garden while playing with Michael's son,   Anthony  Anthony  . At the funeral,   Salvatore Tessio  Salvatore Tessio   arranges a meeting between Michael and Don Barzini, signalling his treachery as Vito had warned. The meeting is set for the same day as the christening of Connie's son, to whom Michael will stand as godfather. As the christening proceeds, Corleone assassins, acting on Michael's orders, murder the other New York dons and Moe Greene. Tessio is told that Michael is aware of his betrayal and taken off to his death. After Carlo is questioned by Michael on his involvement in setting up Sonny's murder and confesses he was contacted by Barzini,   Peter Clemenza  Peter Clemenza   kills him with a wire   garrote  garrote  . Michael is confronted by Connie, who accuses him of having her husband killed. He denies killing Carlo when questioned by Kay, an answer she accepts. As Kay watches warily, Michael receives his   capos  capos  , who address him as the new Don Corleone.\n"
     ]
    }
   ],
   "source": [
    "print (titles[0])\n",
    "print (genres[0])\n",
    "print (synopses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del texto\n",
    "\n",
    "\n",
    "Para analizar el texto debemos estudiar la frecuencia de las palabras, es decir, separar el texto en unidades sintácticas o *tokens*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer', 'science', 'is', 'no', 'more', 'about', 'computers', 'than', 'astronomy', 'is', 'about', 'telescopes', '.', 'Edsger', 'Dijkstra']\n"
     ]
    }
   ],
   "source": [
    "# e.g.:\n",
    "from nltk.tokenize import word_tokenize\n",
    "text1 = \"Computer science is no more about computers than astronomy is about telescopes. Edsger Dijkstra\"\n",
    "tokens = word_tokenize(text1)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Separar primero por oraciones y luego por palabras\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # Eliminar los tokens que no son letras (e.g. 35, ';', '#', etc.)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "totalvocab_tokenized = []\n",
    "for i in synopses:\n",
    "    allwords_tokenized = tokenize(i.decode('utf-8').strip())\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 4: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-220f7af97947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotalvocab_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynopses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mallwords_stemmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for each item in 'synopses', tokenize/stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtotalvocab_stemmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallwords_stemmed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#extend the 'totalvocab_stemmed' list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-c30fe74c74e8>\u001b[0m in \u001b[0;36mtokenize_and_stem\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mfiltered_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mstems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/TeachJob/DiploDatos/python_demos/local/lib/python2.7/site-packages/nltk/stem/snowball.pyc\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;31m# Map the different apostrophe characters to a single consistent one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         word = (word.replace(\"\\u2019\", \"\\x27\")\n\u001b[0m\u001b[1;32m   1218\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\u2018\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\x27\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                     .replace(\"\\u201B\", \"\\x27\"))\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 4: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in synopses:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay en total 3014 tokens \n",
      "\n",
      "['plot', 'edit', 'edit', 'edit', 'on', 'the', 'day', 'of', 'his', 'only', 'daughter', \"'s\", 'wedding', 'vito', 'corleone', 'hears', 'requests', 'in', 'his', 'role', 'as', 'the', 'godfather', 'the', 'don', 'of', 'a', 'new', 'york', 'crime', 'family', 'vito', \"'s\", 'youngest', 'son', 'michael', 'in', 'a', 'marine', 'corps', 'uniform', 'introduces', 'his', 'girlfriend', 'kay', 'adams', 'to', 'his', 'family', 'at']\n"
     ]
    }
   ],
   "source": [
    "print('Hay en total ' + str(len(totalvocab_tokenized)) + ' tokens \\n')\n",
    "len(totalvocab_tokenized)\n",
    "print (totalvocab_tokenized[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar clusters con Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos que hacer el *embeding*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 143)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(synopses) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 4, 1, 3, 1, 0, 2, 0, 1, 3, 2, 1, 1, 1, 4, 0, 2, 4, 4, 0, 1, 1, 0, 3, 1, 4, 4, 1, 3, 2, 3, 1, 3, 3, 3, 3, 4, 3, 3, 2, 2, 4, 4, 4, 0, 0, 0, 3, 3, 3, 1, 4, 3, 1, 3, 4, 3, 2, 2, 0, 4, 3, 2, 4, 2, 4, 1, 1, 0, 4, 1, 0, 4, 2, 1, 4, 2, 2, 3, 2, 0, 1, 1, 0, 2, 1, 3, 4, 3, 1, 1, 1, 1, 0, 2, 1, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print (clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El cluster 0 tiene 15 elementos\n",
      "El cluster 1 tiene 26 elementos\n",
      "El cluster 2 tiene 18 elementos\n",
      "El cluster 3 tiene 21 elementos\n",
      "El cluster 4 tiene 20 elementos\n"
     ]
    }
   ],
   "source": [
    "# Recuento del número de elementos en cada cluster\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print ('El cluster %i tiene %i elementos' % (i, clusters.count(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "films = { 'title': titles, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
    "frame = pd.DataFrame(films, index = [clusters] , columns = ['title', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>[u' Crime', u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>[u' Biography', u' Drama', u' History']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>[u' Biography', u' Drama', u' Sport']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>[u' Drama', u' Mystery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Wizard of Oz</td>\n",
       "      <td>[u' Adventure', u' Family', u' Fantasy', u' Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>[u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "4         The Shawshank Redemption   \n",
       "4                 Schindler's List   \n",
       "1                      Raging Bull   \n",
       "3                       Casablanca   \n",
       "1  One Flew Over the Cuckoo's Nest   \n",
       "0               Gone with the Wind   \n",
       "2                     Citizen Kane   \n",
       "0                 The Wizard of Oz   \n",
       "1                          Titanic   \n",
       "\n",
       "                                               genre  \n",
       "4                             [u' Crime', u' Drama']  \n",
       "4            [u' Biography', u' Drama', u' History']  \n",
       "1              [u' Biography', u' Drama', u' Sport']  \n",
       "3                  [u' Drama', u' Romance', u' War']  \n",
       "1                                        [u' Drama']  \n",
       "0                  [u' Drama', u' Romance', u' War']  \n",
       "2                           [u' Drama', u' Mystery']  \n",
       "0  [u' Adventure', u' Family', u' Fantasy', u' Mu...  \n",
       "1                           [u' Drama', u' Romance']  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Wizard of Oz</td>\n",
       "      <td>[u' Adventure', u' Family', u' Fantasy', u' Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>[u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E.T. the Extra-Terrestrial</td>\n",
       "      <td>[u' Adventure', u' Family', u' Sci-Fi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinatown</td>\n",
       "      <td>[u' Drama', u' Mystery', u' Thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Fair Lady</td>\n",
       "      <td>[u' Drama', u' Family', u' Musical', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben-Hur</td>\n",
       "      <td>[u' Adventure', u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doctor Zhivago</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Exorcist</td>\n",
       "      <td>[u' Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Smith Goes to Washington</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Out of Africa</td>\n",
       "      <td>[u' Biography', u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Close Encounters of the Third Kind</td>\n",
       "      <td>[u' Drama', u' Sci-Fi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Graduate</td>\n",
       "      <td>[u' Comedy', u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Double Indemnity</td>\n",
       "      <td>[u' Crime', u' Drama', u' Film-Noir', u' Thril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>[u' Biography', u' Drama', u' Musical']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                  Gone with the Wind   \n",
       "0                    The Wizard of Oz   \n",
       "0                        Forrest Gump   \n",
       "0          E.T. the Extra-Terrestrial   \n",
       "0                           Chinatown   \n",
       "0                        My Fair Lady   \n",
       "0                             Ben-Hur   \n",
       "0                      Doctor Zhivago   \n",
       "0                        The Exorcist   \n",
       "0        Mr. Smith Goes to Washington   \n",
       "0                       Out of Africa   \n",
       "0  Close Encounters of the Third Kind   \n",
       "0                        The Graduate   \n",
       "0                    Double Indemnity   \n",
       "0                 Yankee Doodle Dandy   \n",
       "\n",
       "                                               genre  \n",
       "0                  [u' Drama', u' Romance', u' War']  \n",
       "0  [u' Adventure', u' Family', u' Fantasy', u' Mu...  \n",
       "0                           [u' Drama', u' Romance']  \n",
       "0            [u' Adventure', u' Family', u' Sci-Fi']  \n",
       "0             [u' Drama', u' Mystery', u' Thriller']  \n",
       "0  [u' Drama', u' Family', u' Musical', u' Romance']  \n",
       "0                         [u' Adventure', u' Drama']  \n",
       "0                  [u' Drama', u' Romance', u' War']  \n",
       "0                                       [u' Horror']  \n",
       "0                                        [u' Drama']  \n",
       "0            [u' Biography', u' Drama', u' Romance']  \n",
       "0                            [u' Drama', u' Sci-Fi']  \n",
       "0               [u' Comedy', u' Drama', u' Romance']  \n",
       "0  [u' Crime', u' Drama', u' Film-Noir', u' Thril...  \n",
       "0            [u' Biography', u' Drama', u' Musical']  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3014 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_tokenized)\n",
    "print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(synopses) #fit the vectorizer to synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "films = { 'title': titles, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
    "frame = pd.DataFrame(films, index = [clusters] , columns = ['title', 'cluster', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>3</td>\n",
       "      <td>[u' Crime', u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1</td>\n",
       "      <td>[u' Crime', u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>2</td>\n",
       "      <td>[u' Biography', u' Drama', u' History']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Biography', u' Drama', u' Sport']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>1</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>1</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>3</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Mystery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Wizard of Oz</td>\n",
       "      <td>3</td>\n",
       "      <td>[u' Adventure', u' Family', u' Fantasy', u' Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  cluster  \\\n",
       "3                    The Godfather        3   \n",
       "1         The Shawshank Redemption        1   \n",
       "2                 Schindler's List        2   \n",
       "0                      Raging Bull        0   \n",
       "1                       Casablanca        1   \n",
       "1  One Flew Over the Cuckoo's Nest        1   \n",
       "3               Gone with the Wind        3   \n",
       "0                     Citizen Kane        0   \n",
       "3                 The Wizard of Oz        3   \n",
       "0                          Titanic        0   \n",
       "\n",
       "                                               genre  \n",
       "3                             [u' Crime', u' Drama']  \n",
       "1                             [u' Crime', u' Drama']  \n",
       "2            [u' Biography', u' Drama', u' History']  \n",
       "0              [u' Biography', u' Drama', u' Sport']  \n",
       "1                  [u' Drama', u' Romance', u' War']  \n",
       "1                                        [u' Drama']  \n",
       "3                  [u' Drama', u' Romance', u' War']  \n",
       "0                           [u' Drama', u' Mystery']  \n",
       "3  [u' Adventure', u' Family', u' Fantasy', u' Mu...  \n",
       "0                           [u' Drama', u' Romance']  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Biography', u' Drama', u' Sport']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Mystery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunset Blvd.</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Film-Noir']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Mystery', u' Sci-Fi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Comedy', u' Musical', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gandhi</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Biography', u' Drama', u' History']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Here to Eternity</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Sport']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Musical', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Good, the Bad and the Ugly</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Western']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Comedy', u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midnight Cowboy</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Annie Hall</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Comedy', u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tootsie</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Comedy', u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Crime', u' Drama', u' Fantasy', u' Mystery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Network</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Music']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>0</td>\n",
       "      <td>[u' Drama', u' Romance']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  cluster  \\\n",
       "0                     Raging Bull        0   \n",
       "0                    Citizen Kane        0   \n",
       "0                         Titanic        0   \n",
       "0                    Sunset Blvd.        0   \n",
       "0           2001: A Space Odyssey        0   \n",
       "0             Singin' in the Rain        0   \n",
       "0                    12 Angry Men        0   \n",
       "0                          Gandhi        0   \n",
       "0           From Here to Eternity        0   \n",
       "0                           Rocky        0   \n",
       "0        A Streetcar Named Desire        0   \n",
       "0            An American in Paris        0   \n",
       "0  The Good, the Bad and the Ugly        0   \n",
       "0                   The Apartment        0   \n",
       "0                 Midnight Cowboy        0   \n",
       "0                      Annie Hall        0   \n",
       "0                         Tootsie        0   \n",
       "0                  The Green Mile        0   \n",
       "0                         Network        0   \n",
       "0                       Nashville        0   \n",
       "0               Wuthering Heights        0   \n",
       "\n",
       "                                              genre  \n",
       "0             [u' Biography', u' Drama', u' Sport']  \n",
       "0                          [u' Drama', u' Mystery']  \n",
       "0                          [u' Drama', u' Romance']  \n",
       "0                        [u' Drama', u' Film-Noir']  \n",
       "0                         [u' Mystery', u' Sci-Fi']  \n",
       "0            [u' Comedy', u' Musical', u' Romance']  \n",
       "0                                       [u' Drama']  \n",
       "0           [u' Biography', u' Drama', u' History']  \n",
       "0                 [u' Drama', u' Romance', u' War']  \n",
       "0                            [u' Drama', u' Sport']  \n",
       "0                                       [u' Drama']  \n",
       "0                        [u' Musical', u' Romance']  \n",
       "0                                     [u' Western']  \n",
       "0              [u' Comedy', u' Drama', u' Romance']  \n",
       "0                                       [u' Drama']  \n",
       "0              [u' Comedy', u' Drama', u' Romance']  \n",
       "0              [u' Comedy', u' Drama', u' Romance']  \n",
       "0  [u' Crime', u' Drama', u' Fantasy', u' Mystery']  \n",
       "0                                       [u' Drama']  \n",
       "0                            [u' Drama', u' Music']  \n",
       "0                          [u' Drama', u' Romance']  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora lo limpiamos un poco más: STOPWORDS, STEMMING & TOKENIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS\n",
    "\n",
    "# la primera vez hay que descargar la lista de 'stopwords': nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u\"you're\", u\"you've\", u\"you'll\", u\"you'd\", u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u\"she's\", u'her', u'hers', u'herself', u'it', u\"it's\", u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u\"that'll\", u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u\"don't\", u'should', u\"should've\", u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u\"aren't\", u'couldn', u\"couldn't\", u'didn', u\"didn't\", u'doesn', u\"doesn't\", u'hadn', u\"hadn't\", u'hasn', u\"hasn't\", u'haven', u\"haven't\", u'isn', u\"isn't\", u'ma', u'mightn', u\"mightn't\", u'mustn', u\"mustn't\", u'needn', u\"needn't\", u'shan', u\"shan't\", u'shouldn', u\"shouldn't\", u'wasn', u\"wasn't\", u'weren', u\"weren't\", u'won', u\"won't\", u'wouldn', u\"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'fishes are run'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEMMING\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# e.g.:\n",
    "stemmer.stem('fishes are running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cat', u'are', u'run']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_stem('cats are running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalvocab_stemmed = []\n",
    "for i in synopses:\n",
    "    allwords_stemmed = tokenize_and_stem(i.decode('utf-8').strip()) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 162054 items in vocab_frame\n",
      "  words\n",
      "0  plot\n",
      "1  edit\n",
      "2  edit\n",
      "3  edit\n",
      "4    on\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_stemmed})\n",
    "print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')\n",
    "print(vocab_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.54 s, sys: 64 ms, total: 5.6 s\n",
      "Wall time: 5.53 s\n",
      "(100, 212)\n"
     ]
    }
   ],
   "source": [
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(synopses) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "[u'accept', u'agre', u'allow', u'alon', u'american', u'ani', u'anoth', u'apart', u'appear', u'approach', u'arm', u'armi', u'arrang', u'arriv', u'ask', u'attack', u'attempt', u'away', u'becaus', u'becom', u'befor', u'begin', u'believ', u'bodi', u'bring', u'car', u'carri', u'caus', u'chang', u'charg', u'children', u'citi', u'claim', u'close', u'come', u'command', u'commit', u'confess', u'confront', u'continu', u'convinc', u'daughter', u'day', u'dead', u'death', u'decid', u'despit', u'did', u'die', u'discov']\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print (len(terms))\n",
    "print (terms[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "films = { 'title': titles, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
    "frame = pd.DataFrame(films, index = [clusters] , columns = ['title', 'cluster', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
